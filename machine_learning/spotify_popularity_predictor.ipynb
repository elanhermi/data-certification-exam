{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Popularity Predictor (39%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this challenge is to create a model that predicts the popularity of a song based on its features.\n",
    "\n",
    "The dataset contains a list of tracks with the following characteristics:\n",
    "- `acousticness`: whether the track is acoustic\n",
    "- `danceability`: describes how suitable a track is for dancing\n",
    "- `duration_ms`: duration of the track in milliseconds\n",
    "- `energy`: represents a perceptual measure of intensity and activity\n",
    "- `explicit`: whether the track has explicit lyrics\n",
    "- `id`: id for the track\n",
    "- `instrumentalness`: predicts whether a track contains no vocals\n",
    "- `key`: the key the track is in\n",
    "- `liveness`: detects the presence of an audience in the recording\n",
    "- `loudness`: the overall loudness of a track in decibels\n",
    "- `mode`: modality of a track\n",
    "- `name`: name of the track\n",
    "- `popularity`: popularity of the track\n",
    "- `release_date`: release date\n",
    "- `speechiness`: detects the presence of spoken words in a track\n",
    "- `tempo`: overall estimated tempo of a track in beats per minute\n",
    "- `valence`: describes the musical positiveness conveyed by a track\n",
    "- `artist`: artist who performed the track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "**üìù Load the `spotify_popularity_train.csv` dataset from the provided URL. Display the first few rows. Perform the usual cleaning operations. Store the result in a `DataFrame` named `data`.**\n",
    "\n",
    "üëâ Do not forget to clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/spotify_popularity_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65400</td>\n",
       "      <td>0.499</td>\n",
       "      <td>219827</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0</td>\n",
       "      <td>0B6BeEUd6UwFlbsHMQKjob</td>\n",
       "      <td>0.00409</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>-16.435</td>\n",
       "      <td>1</td>\n",
       "      <td>Back in the Goodle Days</td>\n",
       "      <td>40</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>149.460</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>John Hartford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00592</td>\n",
       "      <td>0.439</td>\n",
       "      <td>483948</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0</td>\n",
       "      <td>5Gpx4lJy3vKmIvjwbiR5c8</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>-8.497</td>\n",
       "      <td>1</td>\n",
       "      <td>Worlds Which Break Us - Intro Mix</td>\n",
       "      <td>22</td>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>138.040</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>Driftmoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.73400</td>\n",
       "      <td>0.523</td>\n",
       "      <td>245693</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0</td>\n",
       "      <td>7MxuUYqrCIy93h1EEHrIrL</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>-11.506</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm The Greatest Star</td>\n",
       "      <td>40</td>\n",
       "      <td>1968-09-01</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>75.869</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>Barbra Streisand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0       0.65400         0.499       219827   0.190         0   \n",
       "1       0.00592         0.439       483948   0.808         0   \n",
       "2       0.73400         0.523       245693   0.288         0   \n",
       "\n",
       "                       id  instrumentalness  key  liveness  loudness  mode  \\\n",
       "0  0B6BeEUd6UwFlbsHMQKjob           0.00409    7    0.0898   -16.435     1   \n",
       "1  5Gpx4lJy3vKmIvjwbiR5c8           0.14000    2    0.0890    -8.497     1   \n",
       "2  7MxuUYqrCIy93h1EEHrIrL           0.00000    0    0.0771   -11.506     1   \n",
       "\n",
       "                                name  popularity release_date  speechiness  \\\n",
       "0            Back in the Goodle Days          40         1971       0.0454   \n",
       "1  Worlds Which Break Us - Intro Mix          22   2015-02-02       0.0677   \n",
       "2              I'm The Greatest Star          40   1968-09-01       0.2140   \n",
       "\n",
       "     tempo  valence            artist  \n",
       "0  149.460   0.4300     John Hartford  \n",
       "1  138.040   0.0587         Driftmoon  \n",
       "2   75.869   0.4640  Barbra Streisand  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(url)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of missing values\n",
    "data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "#Replacing missing artists\n",
    "data.artist.replace(np.nan, \"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking distribution and identifying outliers\n",
    "data[['loudness']].boxplot()\n",
    "\n",
    "#Using a Robust Scaler on Loudness\n",
    "r_scaler = RobustScaler()\n",
    "r_scaler.fit(data[['loudness']])\n",
    "data['loudness'] = r_scaler.transform(data[['loudness']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Harmonizing release date keeping the year only\n",
    "def year_only(date):\n",
    "    date = date[0:4]\n",
    "    return date\n",
    "    \n",
    "data['year'] = data.release_date.apply(year_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c5_data_cleaning\",\n",
    "    data=data).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù We want to use a metric that measures the prediction error in the same unit than `popularity`. In addition, it should strongly penalize largest errors. Which sklearn's [metric](https://scikit-learn.org/stable/modules/model_evaluation.html) should we use? Store its exact name as string below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = \"mean squared error\"\n",
    "#we will use the root mean squared error to both strongly penalize errors and measure the prediction error in the same unit as popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Let's build a baseline model using only the numerical features in our dataset.**\n",
    "- Build `X_baseline` with only numerical features\n",
    "- Build `y` your target containing the `popularity`\n",
    "- Then 5 times cross validate the baseline linear model of your choice (do not fine tune it)\n",
    "- Store your mean performance in a `float` variable named `baseline_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0008176493102242333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing X and y\n",
    "X_baseline = data[['acousticness', 'artist', 'danceability', 'duration_ms', 'energy', 'explicit', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'year', 'speechiness', 'tempo', 'valence']]\n",
    "y = data[['popularity']]\n",
    "\n",
    "# Baseline model that predicts \"median\"\n",
    "baseline_model = DummyRegressor(strategy=\"median\") \n",
    "\n",
    "# cross validate baseline\n",
    "cv_results = cross_validate(baseline_model, X_baseline, y) \n",
    "baseline_score = cv_results['test_score'].mean()\n",
    "baseline_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"baseline\",\n",
    "    scoring=scoring,\n",
    "    baseline_score=baseline_score).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Let's now use the features that we left aside: `release_date` and `artist` to improve the performance of our model. We'll create them manually in a train vs. test context first (and pipeline them later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holdout\n",
    "**üìù Create the 4 variables `X_train` `y_train`, `X_test`, `y_test` with a 50% split with random sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_baseline, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### year\n",
    "\n",
    "**üìù Create `X_train_year` and `X_test_year` by adding the new column `year` containing the release year of the track as integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_year = X_train\n",
    "X_test_year = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### artist\n",
    "\n",
    "How could we use the `artist` column? There are too many artists to one hot encode it.  \n",
    "We could instead create an `artist_popularity` feature containing the mean popularity of an artist, computed as the mean popularity of all tracks the artist released _on the train set_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process artist popularity from the Training set\n",
    "\n",
    "**üìù Compute and store the `artist_popularity` as a new pandas `Series`**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = data.groupby(by='artist').mean()\n",
    "data_2 = data_2.rename(columns={'popularity': 'artist_popularity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n       'speechiness', 'tempo', 'valence'],\n      dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-18aab23887c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/backinthessr/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8105\u001b[0m         \u001b[0;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8106\u001b[0m         \"\"\"\n\u001b[0;32m-> 8107\u001b[0;31m         return self._join_compat(\n\u001b[0m\u001b[1;32m   8108\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8109\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/backinthessr/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   8130\u001b[0m                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8131\u001b[0m                 )\n\u001b[0;32m-> 8132\u001b[0;31m             return merge(\n\u001b[0m\u001b[1;32m   8133\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8134\u001b[0m                 \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/backinthessr/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/backinthessr/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/backinthessr/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"columns overlap but no suffix specified: {to_rename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n       'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\n       'speechiness', 'tempo', 'valence'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "X_train.join(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the artist popularity to `X_train_year`\n",
    "\n",
    "**üìù Create a new DataFrame `X_train_engineered` which adds a new column to the existing `X_train_year` with the `artist_popularity` corresponding to the song's artist.** \n",
    "\n",
    "üö® Make sure that the target `popularity` does not end up in `X_train_engineered` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artist</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>year</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>0.3740</td>\n",
       "      <td>Dave Loggins</td>\n",
       "      <td>0.563</td>\n",
       "      <td>246080</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.312399</td>\n",
       "      <td>1</td>\n",
       "      <td>1974</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>133.493</td>\n",
       "      <td>0.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28341</th>\n",
       "      <td>0.9650</td>\n",
       "      <td>Barney Kessel</td>\n",
       "      <td>0.662</td>\n",
       "      <td>219107</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-1.353819</td>\n",
       "      <td>1</td>\n",
       "      <td>1956</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>135.634</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25281</th>\n",
       "      <td>0.8180</td>\n",
       "      <td>Nappy Brown</td>\n",
       "      <td>0.368</td>\n",
       "      <td>147507</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.305944</td>\n",
       "      <td>1</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>164.055</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>Janis Joplin</td>\n",
       "      <td>0.339</td>\n",
       "      <td>321773</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>4</td>\n",
       "      <td>0.834</td>\n",
       "      <td>-0.045320</td>\n",
       "      <td>0</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>99.542</td>\n",
       "      <td>0.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14424</th>\n",
       "      <td>0.7770</td>\n",
       "      <td>Gal Costa</td>\n",
       "      <td>0.622</td>\n",
       "      <td>112467</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-1.401560</td>\n",
       "      <td>1</td>\n",
       "      <td>1967</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>82.449</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>0.0760</td>\n",
       "      <td>The Dark Tenor</td>\n",
       "      <td>0.466</td>\n",
       "      <td>238133</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.011969</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>154.154</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34590</th>\n",
       "      <td>0.3240</td>\n",
       "      <td>J. Cole</td>\n",
       "      <td>0.667</td>\n",
       "      <td>241160</td>\n",
       "      <td>0.6080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.507262</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>99.992</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20039</th>\n",
       "      <td>0.4340</td>\n",
       "      <td>Grupo Bryndis</td>\n",
       "      <td>0.692</td>\n",
       "      <td>175053</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>11</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.504707</td>\n",
       "      <td>0</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>88.802</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17572</th>\n",
       "      <td>0.0433</td>\n",
       "      <td>Akinyele</td>\n",
       "      <td>0.636</td>\n",
       "      <td>201533</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>7</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.707235</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>81.400</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21074</th>\n",
       "      <td>0.9290</td>\n",
       "      <td>Sons of the Pioneers</td>\n",
       "      <td>0.220</td>\n",
       "      <td>136027</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>2</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.739107</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>49.394</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26158 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acousticness                artist  danceability  duration_ms  energy  \\\n",
       "16904        0.3740          Dave Loggins         0.563       246080  0.4180   \n",
       "28341        0.9650         Barney Kessel         0.662       219107  0.0711   \n",
       "25281        0.8180           Nappy Brown         0.368       147507  0.5470   \n",
       "3715         0.0201          Janis Joplin         0.339       321773  0.7880   \n",
       "14424        0.7770             Gal Costa         0.622       112467  0.2340   \n",
       "...             ...                   ...           ...          ...     ...   \n",
       "4060         0.0760        The Dark Tenor         0.466       238133  0.7460   \n",
       "34590        0.3240               J. Cole         0.667       241160  0.6080   \n",
       "20039        0.4340         Grupo Bryndis         0.692       175053  0.8180   \n",
       "17572        0.0433              Akinyele         0.636       201533  0.7510   \n",
       "21074        0.9290  Sons of the Pioneers         0.220       136027  0.1450   \n",
       "\n",
       "       explicit  instrumentalness  key  liveness  loudness  mode  year  \\\n",
       "16904         0          0.000000    4     0.102  0.312399     1  1974   \n",
       "28341         0          0.773000    8     0.108 -1.353819     1  1956   \n",
       "25281         0          0.000057    0     0.187  0.305944     1  1984   \n",
       "3715          0          0.001520    4     0.834 -0.045320     0  1971   \n",
       "14424         0          0.000002    0     0.118 -1.401560     1  1967   \n",
       "...         ...               ...  ...       ...       ...   ...   ...   \n",
       "4060          0          0.000000    2     0.600  1.011969     0  2019   \n",
       "34590         1          0.000198    1     0.426  0.507262     1  2013   \n",
       "20039         0          0.000053   11     0.288  0.504707     0  1994   \n",
       "17572         1          0.000241    7     0.167  0.707235     1  1999   \n",
       "21074         0          0.000259    2     0.251 -0.739107     1  1959   \n",
       "\n",
       "       speechiness    tempo  valence  \n",
       "16904       0.0287  133.493    0.347  \n",
       "28341       0.0597  135.634    0.497  \n",
       "25281       0.0428  164.055    0.936  \n",
       "3715        0.3100   99.542    0.539  \n",
       "14424       0.1140   82.449    0.833  \n",
       "...            ...      ...      ...  \n",
       "4060        0.0398  154.154    0.309  \n",
       "34590       0.2160   99.992    0.475  \n",
       "20039       0.0370   88.802    0.844  \n",
       "17572       0.2990   81.400    0.562  \n",
       "21074       0.0334   49.394    0.311  \n",
       "\n",
       "[26158 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_year "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the artist popularity to `X_test_year`\n",
    "\n",
    "**üìù Similarily, create a new DataFrame `X_test_engineered` which also adds a new column to the existing `X_test_year` with the `artist_popularity` corresponding to the song's artist, computed from the training set.**\n",
    "\n",
    "üö®**If an artist has never been seen in the training set, use the global mean popularity of all the tracks of `X_train`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "_ = pd.concat([X_train_engineered, X_test_engineered])\n",
    "\n",
    "ChallengeResult(\"c7_feature_engineering\",\n",
    "    shape = _.shape,\n",
    "    cols = _.columns,\n",
    "    years = _.get(\"year\"),\n",
    "    popularities = _.get(\"artist_popularity\"),\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "**üìù Let's see how these features impact the performance of our model. Retrain the same baseline model on numerical values only, but adding the new features `year` and `artist_popularity`, and see how the performance is impacted. Save the performance in a `float` variable named `score_engineered`**\n",
    "\n",
    "üëâ Do not fine tune the model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c7_score_engineering\",\n",
    "    scoring=scoring,\n",
    "    score_engineered=score_engineered).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "\n",
    "**üìù Let's create a full sklearn preprocessing pipeline called `preproc`. It should integrate our feature engineering for `year` and `artist_popularity`, as well as any other preprocessing of your choice**\n",
    "\n",
    "**Store also the number of columns/feature after preprocessing your inputs in a variable `col_number`**\n",
    "\n",
    "**üö®‚ö†Ô∏è Advice: SKIP the `ArtistPopularityTransformer` if you don't have time to do it. It is better for you to have a working pipeline rather than NO pipeline at all**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# üëâ Do not hesitate to reload clean new dataset if you need a fresh start\n",
    "y = data.popularity\n",
    "X = data.drop(\"popularity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to visualize your pipeline as you build it\n",
    "from sklearn import set_config; set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We give you below the skeleton of the custom ArtistPopularityTransformer to complete\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArtistPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        process artist mean popularity from artists songs popularity\n",
    "        process song global mean popularity\n",
    "        \"\"\"\n",
    "\n",
    "        # process artist popularity\n",
    "\n",
    "        # process mean popularity\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        apply artist mean popularity vs song global mean popularity to songs\n",
    "        \"\"\"\n",
    "\n",
    "        # inject artist popularity\n",
    "\n",
    "        # fills popularity of unknown artists with song global mean popularity\n",
    "\n",
    "        return # TODO return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your preproc here for the correctors\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"c6_preprocessing\",\n",
    "    col_number=col_number\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "üìù Time to optimize \n",
    "\n",
    "- **Add an estimator to your pipeline (only from scikit-learn)** \n",
    "\n",
    "- **Train your pipeline and fine-tune (optimize) your estimator to get the best prediction score**\n",
    "\n",
    "- **You must create 2 pipelines (one with a linear model, one with an ensemble model)**\n",
    "\n",
    "Then, \n",
    "\n",
    "- Save your two best 5-time cross-validated scores as _float_: `score_linear` and `score_ensemble`\n",
    "\n",
    "- Save your two best trained pipelines as _Pipeline_ objects: `pipe_linear` and `pipe_ensemble`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save your results\n",
    "\n",
    "Run the following cell to save your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "pipe_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "pipe_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\"c8_c9_c11_c13_model_tuning\",\n",
    "    scoring = scoring,\n",
    "    score_linear=score_linear,\n",
    "    score_ensemble=score_ensemble).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API \n",
    "\n",
    "Time to put a pipeline in production!\n",
    "\n",
    "üëâ Go to https://github.com/lewagon/data-certification-api and follow instructions\n",
    "\n",
    "**This final part is independent from the above notebook**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.003px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
